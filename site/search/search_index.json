{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"DMD Autoencoder Prediction, estimation, and control of dynamical systems remains challenging due to the nonlinear dynamics most systems hold. However, recent advances in leveraging deep learning to identify coordinate transformations that make strongly nonlinear dynamics approximately linear have enabled analyzing nonlinear systems. We propose a simple approach to find these coordinate transformations. The proposed approach identifies a nonlinear mapping to a space where dynamics are linear using a deep autoencoder. The autoencoder minimizes the loss of the autoencoder reconstruction and dynamic mode decomposition reconstruction of the latent space trajectories. This simple DMD autoencoder is tested on dynamical system time series datasets, including the pendulum and fluid flow around a cylinder. The initial research steps were to reproduce the results in \"Deep learning for universal linear embeddings of nonlinear dynamics\" by Lusch et al [1] . In this process, we rebuilt their code in an upgraded library Tensorflow 2.0. Since the performance of the Koopman autoencoder highly depended on the weight initialization, we developed a simple Dynamic Mode Decomposition (DMD) autoencoder as a pretrain to Koopman autoencoder model. This is a collection of Python subroutines and examples that illustrate how to train a Dynamic Mode Decomposition autoencoder. Dependencies Python >= 3.7 numpy >= 1.19.1 tensorflow >= 2.0 matplotlib >= 3.3.1 pydmd >=0.3 References [1] Bethany Lusch, J. Nathan Kutz, and Steven L. Brunton. Deep learning for universal linear embeddings of nonlinear dynamics. Nature Communications, 9(1):4950, 2018. [2] J. H. Tu, C. W. Rowley, D. M. Luchtenburg, S. L. Brunton, and J. Nathan Kutz. On dynamic mode decomposition: theory and applications. J. Comp. Dyn., 1(2):391-421, 2014. License MIT Important Python subroutines The most important Python subroutines are: dmd_machine: 1 2 3 dmd_machine/autoencoder_network.py dmd_machine/dmd_ae_machine.py dmd_machine/loss_function.py data: 1 data/Data.py driver/runfile: 1 2 3 train_discrete_dataset_machine.py train_pendulum_machine.py train_fluid_flow_machine.py About the Authors Mathematics Department, San Diego State University Research project under the supervision of Professor Christopher Curtis (ccurtis@sdsu.edu). Research group: Opal Issan- Applied Mathematics undergraduate student (opal.issan@gmail.com) Jay Lago- Computational Science PhD student (jaylago@gmail.com) Joseph Diaz- Applied Mathematics Undergraduate student (joseph.a.g.diaz@gmail.com) Robby Simpson- Applied Mathematics Masters student (robby.c.simpson@gmail.com)","title":"Home"},{"location":"#dmd-autoencoder","text":"Prediction, estimation, and control of dynamical systems remains challenging due to the nonlinear dynamics most systems hold. However, recent advances in leveraging deep learning to identify coordinate transformations that make strongly nonlinear dynamics approximately linear have enabled analyzing nonlinear systems. We propose a simple approach to find these coordinate transformations. The proposed approach identifies a nonlinear mapping to a space where dynamics are linear using a deep autoencoder. The autoencoder minimizes the loss of the autoencoder reconstruction and dynamic mode decomposition reconstruction of the latent space trajectories. This simple DMD autoencoder is tested on dynamical system time series datasets, including the pendulum and fluid flow around a cylinder. The initial research steps were to reproduce the results in \"Deep learning for universal linear embeddings of nonlinear dynamics\" by Lusch et al [1] . In this process, we rebuilt their code in an upgraded library Tensorflow 2.0. Since the performance of the Koopman autoencoder highly depended on the weight initialization, we developed a simple Dynamic Mode Decomposition (DMD) autoencoder as a pretrain to Koopman autoencoder model. This is a collection of Python subroutines and examples that illustrate how to train a Dynamic Mode Decomposition autoencoder.","title":"DMD Autoencoder"},{"location":"#dependencies","text":"Python >= 3.7 numpy >= 1.19.1 tensorflow >= 2.0 matplotlib >= 3.3.1 pydmd >=0.3","title":"Dependencies"},{"location":"#references","text":"[1] Bethany Lusch, J. Nathan Kutz, and Steven L. Brunton. Deep learning for universal linear embeddings of nonlinear dynamics. Nature Communications, 9(1):4950, 2018. [2] J. H. Tu, C. W. Rowley, D. M. Luchtenburg, S. L. Brunton, and J. Nathan Kutz. On dynamic mode decomposition: theory and applications. J. Comp. Dyn., 1(2):391-421, 2014.","title":"References"},{"location":"#license","text":"MIT","title":"License"},{"location":"#important-python-subroutines","text":"The most important Python subroutines are: dmd_machine: 1 2 3 dmd_machine/autoencoder_network.py dmd_machine/dmd_ae_machine.py dmd_machine/loss_function.py data: 1 data/Data.py driver/runfile: 1 2 3 train_discrete_dataset_machine.py train_pendulum_machine.py train_fluid_flow_machine.py","title":"Important Python subroutines"},{"location":"#about-the-authors","text":"Mathematics Department, San Diego State University Research project under the supervision of Professor Christopher Curtis (ccurtis@sdsu.edu). Research group: Opal Issan- Applied Mathematics undergraduate student (opal.issan@gmail.com) Jay Lago- Computational Science PhD student (jaylago@gmail.com) Joseph Diaz- Applied Mathematics Undergraduate student (joseph.a.g.diaz@gmail.com) Robby Simpson- Applied Mathematics Masters student (robby.c.simpson@gmail.com)","title":"About the Authors"},{"location":"dmd/","text":"Dynamic Mode Decomposition and the Koopman Operator Let x_{t} x_{t} be the state vector of a nonlinear dynamic system. In order to create a linear model, our goal is to fit the dynamical system states to a model of the form: (1) $$\\frac{d}{d t} x = Ax $$ (2) $$x_{t+1} = Ax_{t} $$ A nonlinear system can be represented in term of an infinite dimensional operator acting on a Hilbert space of measurement function of the state of the system. The Koopman operator is linear, yet infinite-dimensional. An approximation of the Koopman Operator can be obtained by variants of the Dynamic Mode Decomposition algorithm. The Dynamic Mode Decomposition developed by Schmid is a dimensionality reduction algorithm. Given time series dataset, the exact Dynamic Mode Decomposition computes the best fit operator A that advances the system measurements in time [2] . The time series dataset can be arranged into two matrices, X X and X' X' : (3) \\begin{equation} \\label{eq:3} X= \\begin{bmatrix} \\vert & \\vert & & \\vert\\\\ x_{0} & x_{1} & ...& x_{m-1} \\\\ \\vert & \\vert & & \\vert \\end{bmatrix} \\end{equation} \\begin{equation} \\label{eq:3} X= \\begin{bmatrix} \\vert & \\vert & & \\vert\\\\ x_{0} & x_{1} & ...& x_{m-1} \\\\ \\vert & \\vert & & \\vert \\end{bmatrix} \\end{equation} (4) \\begin{equation} \\label{eq:4} X' = \\begin{bmatrix} \\vert & \\vert & & \\vert\\\\ x_{1} & x_{2} & ...& x_{m} \\\\ \\vert & \\vert & & \\vert \\end{bmatrix} \\end{equation} \\begin{equation} \\label{eq:4} X' = \\begin{bmatrix} \\vert & \\vert & & \\vert\\\\ x_{1} & x_{2} & ...& x_{m} \\\\ \\vert & \\vert & & \\vert \\end{bmatrix} \\end{equation} In order to find the matrix A in equation (1) and (2), we solve the linear system with the DMD algorithm. By the singular value decomposition, X \\approx U \\Sigma V^{*} X \\approx U \\Sigma V^{*} where \\tilde{U} \\in \\mathbb{C}^{n \\times r} \\tilde{U} \\in \\mathbb{C}^{n \\times r} , \\tilde{\\Sigma} \\in \\mathbb{C}^{r \\times r} \\tilde{\\Sigma} \\in \\mathbb{C}^{r \\times r} , and \\tilde{V} \\in \\mathbb{C}^{m \\times r} \\tilde{V} \\in \\mathbb{C}^{m \\times r} . Therefore, the matrix A is obtained by A = X'\\tilde{V}\\tilde{\\Sigma}^{-1}\\tilde{U}^{*} A = X'\\tilde{V}\\tilde{\\Sigma}^{-1}\\tilde{U}^{*} . The DMD objective is to minimize the following: (5) \\begin{equation} \\label{eq:5} \\arg \\min _{A}\\left\\| X' - A X \\right\\| _{F}^{2} \\end{equation} \\begin{equation} \\label{eq:5} \\arg \\min _{A}\\left\\| X' - A X \\right\\| _{F}^{2} \\end{equation} There are many ways to measure the accuracy of the DMD fit, a simple way is to evaluate the following expression: (6) \\begin{equation} \\label{eq:6} \\begin{aligned} \\left\\| X'- AX \\right\\| _{F}^{2} = \\left\\| X'- (X' V \\Sigma^{-1} U^{*}) X \\right\\| _{F}^{2}\\\\ = \\left\\| X'- (X' V \\Sigma^{-1} U^{*}) ( U \\Sigma V^{T}) \\right\\| _{F}^{2} \\\\ =\\left\\| X' ( I - V V^{T}) \\right\\| _{F}^{2} \\end{aligned} \\end{equation} \\begin{equation} \\label{eq:6} \\begin{aligned} \\left\\| X'- AX \\right\\| _{F}^{2} = \\left\\| X'- (X' V \\Sigma^{-1} U^{*}) X \\right\\| _{F}^{2}\\\\ = \\left\\| X'- (X' V \\Sigma^{-1} U^{*}) ( U \\Sigma V^{T}) \\right\\| _{F}^{2} \\\\ =\\left\\| X' ( I - V V^{T}) \\right\\| _{F}^{2} \\end{aligned} \\end{equation} An additional approach to evaluate the DMD fit is by comparing the DMD reconstruction data to the time-series input data X X . The DMD reconstruction can be obtained in two different approaches. The first approach is by taking powers of the matrix A A . A more efficient approach is by expanding the system state in terms of the data-driven spectral decomposition. (7) \\begin{equation} \\label{eq:7} x_{k} = \\sum_{i=1}^{r} \\phi_{i} \\lambda_{i}^{k-1} b_{i} = \\Phi \\Lambda^{k-1} b \\end{equation} Where \\Phi \\Phi are the eigenvectors of the A A matrix, \\lambda \\lambda are the eigenvalues of the A A matrix, and b is the mode amplitude. Hence, the DMD reconstruction loss can be computed by the mean squared error of the difference between the input data X X and the spectral decomposition in equation (7).","title":"DMD and Koopman"},{"location":"dmd/#dynamic-mode-decomposition-and-the-koopman-operator","text":"Let x_{t} x_{t} be the state vector of a nonlinear dynamic system. In order to create a linear model, our goal is to fit the dynamical system states to a model of the form: (1) $$\\frac{d}{d t} x = Ax $$ (2) $$x_{t+1} = Ax_{t} $$ A nonlinear system can be represented in term of an infinite dimensional operator acting on a Hilbert space of measurement function of the state of the system. The Koopman operator is linear, yet infinite-dimensional. An approximation of the Koopman Operator can be obtained by variants of the Dynamic Mode Decomposition algorithm. The Dynamic Mode Decomposition developed by Schmid is a dimensionality reduction algorithm. Given time series dataset, the exact Dynamic Mode Decomposition computes the best fit operator A that advances the system measurements in time [2] . The time series dataset can be arranged into two matrices, X X and X' X' : (3) \\begin{equation} \\label{eq:3} X= \\begin{bmatrix} \\vert & \\vert & & \\vert\\\\ x_{0} & x_{1} & ...& x_{m-1} \\\\ \\vert & \\vert & & \\vert \\end{bmatrix} \\end{equation} \\begin{equation} \\label{eq:3} X= \\begin{bmatrix} \\vert & \\vert & & \\vert\\\\ x_{0} & x_{1} & ...& x_{m-1} \\\\ \\vert & \\vert & & \\vert \\end{bmatrix} \\end{equation} (4) \\begin{equation} \\label{eq:4} X' = \\begin{bmatrix} \\vert & \\vert & & \\vert\\\\ x_{1} & x_{2} & ...& x_{m} \\\\ \\vert & \\vert & & \\vert \\end{bmatrix} \\end{equation} \\begin{equation} \\label{eq:4} X' = \\begin{bmatrix} \\vert & \\vert & & \\vert\\\\ x_{1} & x_{2} & ...& x_{m} \\\\ \\vert & \\vert & & \\vert \\end{bmatrix} \\end{equation} In order to find the matrix A in equation (1) and (2), we solve the linear system with the DMD algorithm. By the singular value decomposition, X \\approx U \\Sigma V^{*} X \\approx U \\Sigma V^{*} where \\tilde{U} \\in \\mathbb{C}^{n \\times r} \\tilde{U} \\in \\mathbb{C}^{n \\times r} , \\tilde{\\Sigma} \\in \\mathbb{C}^{r \\times r} \\tilde{\\Sigma} \\in \\mathbb{C}^{r \\times r} , and \\tilde{V} \\in \\mathbb{C}^{m \\times r} \\tilde{V} \\in \\mathbb{C}^{m \\times r} . Therefore, the matrix A is obtained by A = X'\\tilde{V}\\tilde{\\Sigma}^{-1}\\tilde{U}^{*} A = X'\\tilde{V}\\tilde{\\Sigma}^{-1}\\tilde{U}^{*} . The DMD objective is to minimize the following: (5) \\begin{equation} \\label{eq:5} \\arg \\min _{A}\\left\\| X' - A X \\right\\| _{F}^{2} \\end{equation} \\begin{equation} \\label{eq:5} \\arg \\min _{A}\\left\\| X' - A X \\right\\| _{F}^{2} \\end{equation} There are many ways to measure the accuracy of the DMD fit, a simple way is to evaluate the following expression: (6) \\begin{equation} \\label{eq:6} \\begin{aligned} \\left\\| X'- AX \\right\\| _{F}^{2} = \\left\\| X'- (X' V \\Sigma^{-1} U^{*}) X \\right\\| _{F}^{2}\\\\ = \\left\\| X'- (X' V \\Sigma^{-1} U^{*}) ( U \\Sigma V^{T}) \\right\\| _{F}^{2} \\\\ =\\left\\| X' ( I - V V^{T}) \\right\\| _{F}^{2} \\end{aligned} \\end{equation} \\begin{equation} \\label{eq:6} \\begin{aligned} \\left\\| X'- AX \\right\\| _{F}^{2} = \\left\\| X'- (X' V \\Sigma^{-1} U^{*}) X \\right\\| _{F}^{2}\\\\ = \\left\\| X'- (X' V \\Sigma^{-1} U^{*}) ( U \\Sigma V^{T}) \\right\\| _{F}^{2} \\\\ =\\left\\| X' ( I - V V^{T}) \\right\\| _{F}^{2} \\end{aligned} \\end{equation} An additional approach to evaluate the DMD fit is by comparing the DMD reconstruction data to the time-series input data X X . The DMD reconstruction can be obtained in two different approaches. The first approach is by taking powers of the matrix A A . A more efficient approach is by expanding the system state in terms of the data-driven spectral decomposition. (7) \\begin{equation} \\label{eq:7} x_{k} = \\sum_{i=1}^{r} \\phi_{i} \\lambda_{i}^{k-1} b_{i} = \\Phi \\Lambda^{k-1} b \\end{equation} Where \\Phi \\Phi are the eigenvectors of the A A matrix, \\lambda \\lambda are the eigenvalues of the A A matrix, and b is the mode amplitude. Hence, the DMD reconstruction loss can be computed by the mean squared error of the difference between the input data X X and the spectral decomposition in equation (7).","title":"Dynamic Mode Decomposition and the Koopman Operator"},{"location":"example1/","text":"Consider a simple nonlinear discrete spectrum system, described as follows: \\dot{x_{1}} = \\mu x_{1} \\dot{x_{1}} = \\mu x_{1} \\dot{x_{2}} = \\lambda (x_{2} - x_{1}^{2}) \\dot{x_{2}} = \\lambda (x_{2} - x_{1}^{2}) Given the input data we measure the dynamic mode decomposition accuracy by equation (6) and (7). As a result, L_{2} = 3.27 \u00d7 10^{-4} L_{2} = 3.27 \u00d7 10^{-4} and L_{3} = 5.055 \u00d7 10^{-5} L_{3} = 5.055 \u00d7 10^{-5} , whereas in the latent space dataset Y Y , L_{2} = 3.006 \u00d7 10^{-4} L_{2} = 3.006 \u00d7 10^{-4} and L_{3} = 2.703 \u00d7 10^{-4} L_{3} = 2.703 \u00d7 10^{-4} . While the DMD loss decreased, the predictability loss did not improve. There is more room for improvement by adjusting the network's hyper-parameters.","title":"Discrete Dataset"},{"location":"example2/","text":"Consider the simple pendulum which is a nonlinear continuous spectra systems, described as follow: \\dot{x_{1}} = x_{2} \\dot{x_{1}} = x_{2} \\dot{x_{2}} = -\\sin(x_{1}) \\dot{x_{2}} = -\\sin(x_{1}) with the potential function \\frac{1}{2}x_{2}^{2} - \\cos(x_{1}) \\frac{1}{2}x_{2}^{2} - \\cos(x_{1}) . Given the input data we measure the dynamic mode decomposition accuracy by equation (6) and (7). As a result, L_{2} = 1.574 \u00d7 10^{-1} L_{2} = 1.574 \u00d7 10^{-1} and L_{3} = 2.658 \u00d7 10^{-2} L_{3} = 2.658 \u00d7 10^{-2} , whereas in the latent space dataset Y Y , L_{2} = 1.737 \u00d7 10^{-3} L_{2} = 1.737 \u00d7 10^{-3} and L_{3} = 9.51 \u00d7 10^{-4} L_{3} = 9.51 \u00d7 10^{-4} . These results show that the encoder network finds a mapping which the nonlinear dynamics become approximately linear. Training and Testing dataset loss curve.","title":"Pendulum Dataset"},{"location":"example3/","text":"Fluid Flow Dataset Consider the nonlinear mean-field model of fluid flow past a circular cylinder at Reynolds number 100, described by empirical Galerkin model: \\dot{x_{1}} = \\mu x_{1} - \\omega x_{2} + A x_{1} x_{3} \\dot{x_{1}} = \\mu x_{1} - \\omega x_{2} + A x_{1} x_{3} \\dot{x_{2}} = \\omega x_{1} + \\mu x_{2} + A x_{2} x_{3} \\dot{x_{2}} = \\omega x_{1} + \\mu x_{2} + A x_{2} x_{3} \\dot{x_{3}} = -\\lambda (x_{3} - x_{1}^{2} - x_{2}^{2}) \\dot{x_{3}} = -\\lambda (x_{3} - x_{1}^{2} - x_{2}^{2}) Where \\mu=0.1 \\mu=0.1 , \\omega=1 \\omega=1 , A=-0.1 A=-0.1 , \\lambda = 10 \\lambda = 10 . The slow manifold toward the limit cycle, DMD Autoencoder results:","title":"Fluid Flow Dataset"},{"location":"example3/#fluid-flow-dataset","text":"Consider the nonlinear mean-field model of fluid flow past a circular cylinder at Reynolds number 100, described by empirical Galerkin model: \\dot{x_{1}} = \\mu x_{1} - \\omega x_{2} + A x_{1} x_{3} \\dot{x_{1}} = \\mu x_{1} - \\omega x_{2} + A x_{1} x_{3} \\dot{x_{2}} = \\omega x_{1} + \\mu x_{2} + A x_{2} x_{3} \\dot{x_{2}} = \\omega x_{1} + \\mu x_{2} + A x_{2} x_{3} \\dot{x_{3}} = -\\lambda (x_{3} - x_{1}^{2} - x_{2}^{2}) \\dot{x_{3}} = -\\lambda (x_{3} - x_{1}^{2} - x_{2}^{2}) Where \\mu=0.1 \\mu=0.1 , \\omega=1 \\omega=1 , A=-0.1 A=-0.1 , \\lambda = 10 \\lambda = 10 . The slow manifold toward the limit cycle, DMD Autoencoder results:","title":"Fluid Flow Dataset"},{"location":"hyperparams/","text":"","title":"Hyper-parameters"},{"location":"loss/","text":"The simple DMD autoencoder loss function is a combination of three evaluations: Autoencoder reconstruction loss - This ensures that the original trajectories can be recovered. \\begin{equation} \\label{eq:8} L_{1} = MSE \\left| X - g^{-1}(\\tilde{Y}) \\right| \\end{equation} DMD loss - evaluate the linearity of the latent space dynamics. The following is derived in equation (6). \\begin{equation} \\label{eq:9} L_{2} = \\left\\| Y' ( I - V V^{T}) \\right\\| _{F}^{2} \\end{equation} \\begin{equation} \\label{eq:9} L_{2} = \\left\\| Y' ( I - V V^{T}) \\right\\| _{F}^{2} \\end{equation} DMD reconstruction loss - evaluate the DMD least squares fit of the A A matrix. \\begin{equation} \\label{eq:10} L_{3} = MSE\\left| Y - \\tilde{Y} \\right| \\end{equation} The final loss function is L = \\alpha_{1}L_{1} + \\alpha_{2}L_{2} + \\alpha_{3}L_{3} L = \\alpha_{1}L_{1} + \\alpha_{2}L_{2} + \\alpha_{3}L_{3} .","title":"Loss"},{"location":"model/","text":"DMD Autoencoder The figure above illustrates the simple DMD autoencoder architecture. The input time sequential dataset X X is passed to the encoder which is a nonlinear mapping g g . The encoder output is called the latent space y_{k} = g(x_{k}) y_{k} = g(x_{k}) . The latent space Y Y is predicted by the Dynamic Mode Decomposition, \\tilde y_{k+1} \\tilde y_{k+1} = A^{k}y_{0} A^{k}y_{0} . Both the latent space Y Y and predicted latent space \\tilde{Y} \\tilde{Y} are passed to the decoder g^{-1} g^{-1} . Lastly, the decoder outputs g^{-1}(Y) g^{-1}(Y) and g^{-1}(\\tilde{Y}) g^{-1}(\\tilde{Y}) . Important subroutines: dmd_machine/autoencoder_network.py - The Autoencoder network is a Keras sequential model. dmd_machine/dmd_ae_machine.py - The DMD Autoencoder, computes the predicted latent \\tilde{Y} \\tilde{Y} by the dynamic mode decomposition algorithm.","title":"Model"},{"location":"model/#dmd-autoencoder","text":"The figure above illustrates the simple DMD autoencoder architecture. The input time sequential dataset X X is passed to the encoder which is a nonlinear mapping g g . The encoder output is called the latent space y_{k} = g(x_{k}) y_{k} = g(x_{k}) . The latent space Y Y is predicted by the Dynamic Mode Decomposition, \\tilde y_{k+1} \\tilde y_{k+1} = A^{k}y_{0} A^{k}y_{0} . Both the latent space Y Y and predicted latent space \\tilde{Y} \\tilde{Y} are passed to the decoder g^{-1} g^{-1} . Lastly, the decoder outputs g^{-1}(Y) g^{-1}(Y) and g^{-1}(\\tilde{Y}) g^{-1}(\\tilde{Y}) . Important subroutines: dmd_machine/autoencoder_network.py - The Autoencoder network is a Keras sequential model. dmd_machine/dmd_ae_machine.py - The DMD Autoencoder, computes the predicted latent \\tilde{Y} \\tilde{Y} by the dynamic mode decomposition algorithm.","title":"DMD Autoencoder"},{"location":"setup/","text":"1) Check python version is >= 3.7 with the following bash command. 1 2 $ python --version Python 3 .7.6 2) Download the following dependencies: Python >= 3.7 numpy >= 1.19.1 tensorflow >= 2.0 matplotlib >= 3.3.1 pydmd >=0.3 3) Download the full repo . 1 $ git clone <repo>","title":"Setup"}]}